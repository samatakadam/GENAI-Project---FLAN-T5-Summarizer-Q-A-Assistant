#########################################
#
# Samata's FLAN-T5 Model
#
#########################################

import os
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# Import from Hugging Face Transformers
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# Choose an instruction-tuned model
MODEL_NAME = "google/flan-t5-small"

# Lightweight version of FLAN-T5
# About 80 million parameters

print(f"Marvellous FLAN-T5_SUMMARIZER_Q&A_Assistant {MODEL_NAME} model loading.....")

# Load tokenizer
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)

# Load the sequence-to-sequence model
model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)

#############################################################
# This function takes a text prompt and generates output
#############################################################
def Marvelllous_run_flan(prompt: str, max_new_tokens: int = 128) -> str:

    inputs = tokenizer(prompt, return_tensors="pt", truncation=True)

    outputs = model.generate(
        **inputs,
        max_new_tokens=max_new_tokens,
        do_sample=True,
        top_p=0.9,
        temperature=0.7
    )

    return tokenizer.decode(outputs[0], skip_special_tokens=True).strip()


###################################################################
# This function is used for summarisation
###################################################################
def Marvellous_Summarize_text(text: str) -> str:
    prompt = f"Summarize the following text into 4 to 6 bullet points:\n\n{text}"
    return Marvelllous_run_flan(prompt, max_new_tokens=160)


##############################################################################
# Load context from local file
##############################################################################
def Marvellous_load_context(path: str = "context.txt") -> str:
    try:
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return ""


####################################################################
# Answer questions only using given context
####################################################################
def Marvellous_answer_from_content(question: str, context: str) -> str:
    if not context.strip():
        return "Context file not found or empty. Create 'context.txt' first."

    prompt = (
        "You are a helpful assistant. Answer the question only using the context.\n"
        "If the answer is not in the context, reply exactly: Not found.\n\n"
        f"Context:\n{context}\n\n"
        f"Question: {question}\nAnswer:"
    )

    return Marvelllous_run_flan(prompt, max_new_tokens=120)


######################################################
# Entry point function
######################################################
def main():
    print("----------------------------------------------------------------")
    print("----------------------------------- Marvellous FLAN-T5 Model ------------------------------")
    print("1. Summarize the data")
    print("2. Question & Answer over local context.txt")
    print("0. Exit")
    print("----------------------------------------------------------------")

    while True:
        choice = input("\nChoose an option (1/2/0): ").strip()

        if choice == "0":
            print("Thank you for using Marvellous FLAN-T5 Model")
            break

        elif choice == "1":
            print("You have selected Summarization option....")
            print("\nPaste text to summarize. End with a blank line:")

            lines = []
            while True:
                line = input()
                if not line.strip():
                    break
                lines.append(line)

            text = "\n".join(lines).strip()

            if not text:
                print("Marvellous FLAN-T5 says: No text received.")
                continue

            print("\nSummary generated by Marvellous FLAN model:")
            print(Marvellous_Summarize_text(text))

        elif choice == "2":
            ctx = Marvellous_load_context("context.txt")

            if not ctx.strip():
                print("Missing context.txt. Create it in the same folder and try again.")
                continue

            q = input("\nAsk a question about your context to Marvellous FLAN model: ").strip()

            if not q:
                print("No question received.")
                continue

            print("\nAnswer from Marvellous FLAN model:")
            print(Marvellous_answer_from_content(q, ctx))

        else:
            print("Please choose 1, 2, or 0.")


##############################################
# Starter
##############################################
if __name__ == "__main__":
    main()
